{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Deep Convolutional Generative Adversarial Network\n",
    "view https://arxiv.org/pdf/1605.05396.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.MNIST('./MNIST_data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size)\n",
    "mnist_test = torchvision.datasets.MNIST('./MNIST_data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        flattened = input.view(input.shape[0], -1)\n",
    "        return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Unflatten(nn.Module):\n",
    "    def __init__(self, C=128, H=7, W=7):\n",
    "        super(Unflatten, self).__init__()\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        \n",
    "    def forward(self, input):\n",
    "        unflattened = input.view(-1, self.C, self.H, self.W)\n",
    "        return unflattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add_Conditional(nn.Module):\n",
    "    def __init__(self, conditional=torch.zeros(16)):\n",
    "        super(Add_Conditional, self).__init__()\n",
    "        self.conditional= conditional\n",
    "        \n",
    "    def forward(self, input):\n",
    "        print(\"INPUT SHAPE\", input.shape)\n",
    "        conditional_array = np.expand_dims(np.array(self.conditional), axis=1)\n",
    "        conditional_tensor = torch.FloatTensor(conditional_array)\n",
    "        print(\"conditional_tensor\", self.conditional.shape)\n",
    "        concatenated = torch.cat((conditional_tensor, input), dim=1)\n",
    "        return concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_nosie(batch_size, dim=96):\n",
    "    noise = torch.rand(batch_size, dim) * 2 - 1\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(conditional):\n",
    "    print(\"Conditional CNN\", conditional.shape)\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, [5,5], stride=[1,1]),\n",
    "        nn.LeakyReLU(negative_slope=.01),\n",
    "        nn.MaxPool2d([2,2], stride=[2,2]),\n",
    "        nn.Conv2d(32, 64, [5,5], stride=[1,1]),\n",
    "        nn.LeakyReLU(negative_slope=.01),\n",
    "        nn.MaxPool2d([2,2], stride=[2,2]),\n",
    "        Flatten(),\n",
    "        Add_Conditional(conditional=conditional),\n",
    "        Add_Conditional(conditional),\n",
    "        nn.Linear((4*4*64 + 1), (4*4*64)), \n",
    "        nn.LeakyReLU(negative_slope=.01),\n",
    "        nn.Linear((4*4*64), 1)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(conditional, noise_dim=96):\n",
    "    print(\"Conditional\", conditional.shape)\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(noise_dim, 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        Add_Conditional(conditional=conditional),\n",
    "        #1025 b/c added one from conditional\n",
    "        nn.Linear(1025, (7*7*128)),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(7*7*128),\n",
    "        Unflatten(C=128, H=7, W=7),\n",
    "        nn.ConvTranspose2d(128, 64, [4,4], stride=[2,2], padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ConvTranspose2d(64, 1, [4,4], stride=[2,2], padding=1),\n",
    "        nn.Tanh(),\n",
    "        Flatten()\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_optimizer(model, lr=.01, betas=None):\n",
    "    if betas == None:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(scores_real, scores_fake):\n",
    "    true_labels = torch.ones_like(scores_real)\n",
    "    valid_loss = torch.mean((scores_real - true_labels) ** 2) * .5\n",
    "    invalid_loss = torch.mean(scores_fake ** 2) * .5\n",
    "    loss = valid_loss + invalid_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_loss(scores_fake):\n",
    "    true_labels = torch.ones_like(scores_fake)\n",
    "    loss = torch.mean((scores_fake - true_labels) ** 2) * .5\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(images):\n",
    "#     for image in images:\n",
    "    images_np = images.detach().numpy().squeeze()\n",
    "#     side_length = np.sqrt(images.shape[1])\n",
    "#     print(\"side length\", side_length, images.shape)\n",
    "#     assert(side_length % 1 == 0), \"images not square shape\"\n",
    "#     image_show = images[0]\n",
    "#     image_unflattened = np.reshape(image_show, (int(side_length), int(side_length)))\n",
    "#     plt.imshow(image_unflattened)\n",
    "    plt.imshow(images_np[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, image_loader, epochs, num_train_batches=-1):\n",
    "    generator_optimizer = create_optimizer(generator, lr=1e-3, betas=(.5, .999))\n",
    "    discriminator_optimizer = create_optimizer(discriminator, lr=1e-3, betas=(.5, .999))\n",
    "    iters = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i, (examples, labels) in enumerate(image_loader):\n",
    "            if i == num_train_batches:\n",
    "                break\n",
    "            generator_optimizer.zero_grad()\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            z = generate_nosie(batch_size)\n",
    "            images_fake = generator(z, labels)\n",
    "            images_fake_unflattened = images_fake.view(images_fake.shape[0], 1, 28, 28)\n",
    "            scores_fake = discriminator(images_fake_unflattened)\n",
    "            \n",
    "            ##TODO, fix scores_fake 10 class problem\n",
    "            \n",
    "            g_cost = generator_loss(scores_fake)\n",
    "            g_cost.backward(retain_graph=True)\n",
    "            generator_optimizer.step()\n",
    "\n",
    "            scores_real = discriminator(examples, labels)\n",
    "            d_cost = discriminator_loss(scores_real, scores_fake)\n",
    "            d_cost.backward()\n",
    "            discriminator_optimizer.step()\n",
    "            iters += 1\n",
    "            if iters % 100  == 0:\n",
    "                print(\"Iteration:\", iters)\n",
    "                print(\"Discriminator Cost\", d_cost)\n",
    "                print(\"Generator Cost\", g_cost)\n",
    "                show_image(images_fake_unflattened)\n",
    "                \n",
    "\n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional torch.Size([16])\n",
      "Conditional CNN torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "filler_conditonal = torch.zeros(16)\n",
    "generator = generator(filler_conditonal)\n",
    "discriminator = CNN(filler_conditonal)\n",
    "image_loader = train_loader\n",
    "epochs = 5\n",
    "num_train_batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-331-aae081898bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-328-adbc58264a94>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, image_loader, epochs, num_train_batches)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_nosie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mimages_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mimages_fake_unflattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mscores_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_fake_unflattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "train_gan(generator, discriminator, image_loader, epochs, num_train_batches=num_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
