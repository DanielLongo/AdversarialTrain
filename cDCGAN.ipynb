{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Deep Convolutional Generative Adversarial Network\n",
    "view https://arxiv.org/pdf/1605.05396.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.MNIST('./MNIST_data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size)\n",
    "mnist_test = torchvision.datasets.MNIST('./MNIST_data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        flattened = input.view(input.shape[0], -1)\n",
    "        return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Unflatten(nn.Module):\n",
    "    def __init__(self, C=128, H=7, W=7):\n",
    "        super(Unflatten, self).__init__()\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        \n",
    "    def forward(self, input):\n",
    "        unflattened = input.view(-1, self.C, self.H, self.W)\n",
    "        return unflattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add_Conditional(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Add_Conditional, self).__init__()\n",
    "        \n",
    "    def forward(self, input, conditional=None):\n",
    "        print(\"INPUT SHAPE\", input.shape)\n",
    "        conditional_array = np.expand_dims(np.array(conditional), axis=1)\n",
    "        conditional_tensor = torch.FloatTensor(conditional_array)\n",
    "        print(\"conditional_tensor\", conditional.shape)\n",
    "        concatenated = torch.cat((conditional_tensor, input), dim=1)\n",
    "        return concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_noise(batch_size, dim=96):\n",
    "    noise = torch.rand(batch_size, dim) * 2 - 1\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    nn.Conv2d(1, 32, [5,5], stride=[1,1]),\n",
    "    nn.LeakyReLU(negative_slope=.01),\n",
    "    nn.MaxPool2d([2,2], stride=[2,2]),\n",
    "    nn.Conv2d(32, 64, [5,5], stride=[1,1]),\n",
    "    nn.LeakyReLU(negative_slope=.01),\n",
    "    nn.MaxPool2d([2,2], stride=[2,2]),\n",
    "    Flatten(),\n",
    "    Add_Conditional(conditional=conditional),\n",
    "    nn.Linear((4*4*64 + 1), (4*4*64)), \n",
    "    nn.LeakyReLU(negative_slope=.01),\n",
    "    nn.Linear((4*4*64), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, conditional):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, [5,5], stride=[1,1]),\n",
    "            nn.LeakyReLU(negative_slope=.01),\n",
    "            nn.MaxPool2d([2,2], stride=[2,2])\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, [5,5], stride=[1,1]),\n",
    "            nn.LeakyReLU(negative_slope=.01),\n",
    "            nn.MaxPool2d([2,2], stride=[2,2])\n",
    "        )\n",
    "        self.flatten = Flatten()\n",
    "        self.condition_concat = Add_Conditional()\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear((4*4*64 + 1), (4*4*64)), \n",
    "            nn.LeakyReLU(negative_slope=.01),\n",
    "            nn.Linear((4*4*64), 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, conditional):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.condition_concat(out, conditional=conditional)\n",
    "        out = self.linear_layers(out)\n",
    "#         print(\"Conditional CNN\", conditional.shape) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    nn.Linear(noise_dim, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    Add_Conditional(conditional=conditional),\n",
    "    nn.Linear(1025, (7*7*128)),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(7*7*128),\n",
    "    Unflatten(C=128, H=7, W=7),\n",
    "    nn.ConvTranspose2d(128, 64, [4,4], stride=[2,2], padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ConvTranspose2d(64, 1, [4,4], stride=[2,2], padding=1),\n",
    "    nn.Tanh(),\n",
    "    Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self, conditional, noise_dim=96):\n",
    "        super(generator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(noise_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024)\n",
    "        )\n",
    "        self.conditional_concat = Add_Conditional()\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(1024 + 1, (7*7*128)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(7*7*128)\n",
    "        )\n",
    "        self.unflatten = Unflatten(C=128, H=7, W=7)\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, [4,4], stride=[2,2], padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ConvTranspose2d(64, 1, [4,4], stride=[2,2], padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "    def forward(self, x, conditional, noise_dim=96):\n",
    "        out = self.layer1(x)\n",
    "        out = self.conditional_concat(out, conditional=conditional)\n",
    "        out = self.layer2(out)\n",
    "        out = self.unflatten(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.flatten(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_optimizer(model, lr=.01, betas=None):\n",
    "    if betas == None:\n",
    "        optimizer = torch.optim.Adam(model, lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model, lr=lr, betas=betas)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(scores_real, scores_fake):\n",
    "    true_labels = torch.ones_like(scores_real)\n",
    "    valid_loss = torch.mean((scores_real - true_labels) ** 2) * .5\n",
    "    invalid_loss = torch.mean(scores_fake ** 2) * .5\n",
    "    loss = valid_loss + invalid_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_loss(scores_fake):\n",
    "    true_labels = torch.ones_like(scores_fake)\n",
    "    loss = torch.mean((scores_fake - true_labels) ** 2) * .5\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(images):\n",
    "#     for image in images:\n",
    "    images_np = images.detach().numpy().squeeze()\n",
    "#     side_length = np.sqrt(images.shape[1])\n",
    "#     print(\"side length\", side_length, images.shape)\n",
    "#     assert(side_length % 1 == 0), \"images not square shape\"\n",
    "#     image_show = images[0]\n",
    "#     image_unflattened = np.reshape(image_show, (int(side_length), int(side_length)))\n",
    "#     plt.imshow(image_unflattened)\n",
    "    plt.imshow(images_np[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, image_loader, epochs, num_train_batches=-1):\n",
    "    generator_optimizer = create_optimizer(generator.parameters(), lr=1e-3, betas=(.5, .999))\n",
    "    discriminator_optimizer = create_optimizer(discriminator.parameters(), lr=1e-3, betas=(.5, .999))\n",
    "    iters = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i, (examples, labels) in enumerate(image_loader):\n",
    "            if i == num_train_batches:\n",
    "                break\n",
    "            generator_optimizer.zero_grad()\n",
    "            discriminator_optimizer.zero_grad()\n",
    "            z = generate_noise(batch_size)\n",
    "            print(type(z))\n",
    "            print(z.size())\n",
    "            print(type(labels))\n",
    "            print(labels.size())\n",
    "            images_fake = generator(z, labels)\n",
    "            images_fake_unflattened = images_fake.view(images_fake.shape[0], 1, 28, 28)\n",
    "            scores_fake = discriminator(images_fake_unflattened, labels)\n",
    "            \n",
    "            ##TODO, fix scores_fake 10 class problem\n",
    "            \n",
    "            g_cost = generator_loss(scores_fake)\n",
    "            g_cost.backward(retain_graph=True)\n",
    "            generator_optimizer.step()\n",
    "\n",
    "            scores_real = discriminator(examples, labels)\n",
    "            d_cost = discriminator_loss(scores_real, scores_fake)\n",
    "            d_cost.backward()\n",
    "            discriminator_optimizer.step()\n",
    "            iters += 1\n",
    "            if iters % 100  == 0:\n",
    "                print(\"Iteration:\", iters)\n",
    "                print(\"Discriminator Cost\", d_cost)\n",
    "                print(\"Generator Cost\", g_cost)\n",
    "                show_image(images_fake_unflattened)\n",
    "                \n",
    "\n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filler_conditonal = torch.zeros(16)\n",
    "generator = generator(filler_conditonal)\n",
    "discriminator = CNN(filler_conditonal)\n",
    "# generator = generator()\n",
    "# discriminator = CNN()\n",
    "image_loader = train_loader\n",
    "epochs = 5\n",
    "num_train_batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16, 96])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([16])\n",
      "INPUT SHAPE torch.Size([16, 1024])\n",
      "conditional_tensor torch.Size([16])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-aae081898bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-65-aafb627af054>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, image_loader, epochs, num_train_batches)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mimages_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mimages_fake_unflattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mscores_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_fake_unflattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m##TODO, fix scores_fake 10 class problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-bb4b7d08d3ad>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, conditional)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconditional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_gan(generator, discriminator, image_loader, epochs, num_train_batches=num_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClassName(nn.Module):\n",
    "    def __init__(self, conditional=None):\n",
    "        self.first_conv = nn.Conv1D(blah blah)\n",
    "        self.first_pool = nn.MaxPool()\n",
    "    \n",
    "    def forward(self, inp, arg):\n",
    "        out = self.first_conv(inp)\n",
    "        out = self.first_pool(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = ClassName()\n",
    "out = model(x, arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
